{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "theoretical-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# STEP 1 - Generating an artificial dataset:\n",
    "#\n",
    "# reproduced what was done in the video in python.\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import h2o\n",
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "\n",
    "\n",
    "number_of_records = 5000\n",
    "\n",
    "ids = [x for x in range(0,number_of_records)]\n",
    "random_category = ['A', 'B', 'C', 'D']\n",
    "age = [round(random.uniform(18.0, 75.0), 2) for x in range(0, number_of_records)]\n",
    "healthyEating = [round(x, 0) for x in np.random.normal(loc=5, scale=1.0, size=number_of_records)]\n",
    "activeLifestyle = [round(x, 0) for x in np.random.normal(loc=5, scale=1.0, size=number_of_records)]\n",
    "\n",
    "dataframe = pd.DataFrame(ids, columns=['id'])\n",
    "dataframe['random_category'] = [random_category[random.randint(0,len(random_category)-1)] for x in range(0, len(ids))]\n",
    "dataframe['age'] = age\n",
    "dataframe['healthyEating'] = healthyEating\n",
    "dataframe['activeLifestyle'] = activeLifestyle\n",
    "dataframe['activeLifestyle'] = np.where(dataframe['age'] < 30, dataframe['activeLifestyle'] + 1 ,  dataframe['activeLifestyle'])\n",
    "dataframe['income'] = 20000 + ((dataframe['age']*3)**2)\n",
    "dataframe['income'] = np.where(dataframe['activeLifestyle'] < 5, dataframe['income'] * 1.3, dataframe['income'])\n",
    "dataframe['income'] = np.where(dataframe['activeLifestyle'] > 5, dataframe['income'] * 0.7, dataframe['income'])\n",
    "dataframe['income'] = np.where(dataframe['healthyEating'] > 5, dataframe['income'] * 1.1, dataframe['income'])\n",
    "\n",
    "#\n",
    "# add noise to the income column\n",
    "#\n",
    "dataframe['income'] = dataframe['income'] + random.randint(0,4000)\n",
    "dataframe['income'] = np.ceil(dataframe['income']/100)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "clean-premiere",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>3 hours 37 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Berlin</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.32.1.1</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 28 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Gerd_mpc823</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.969 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.0 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         3 hours 37 mins\n",
       "H2O_cluster_timezone:       Europe/Berlin\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.32.1.1\n",
       "H2O_cluster_version_age:    1 month and 28 days\n",
       "H2O_cluster_name:           H2O_from_python_Gerd_mpc823\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.969 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.9.0 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# STEP 2 - start h2o, and import data\n",
    "#\n",
    "\n",
    "h2o.init()\n",
    "\n",
    "#\n",
    "# import  dataframe in h2o instance\n",
    "#\n",
    "dataframe = h2o.H2OFrame(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amazing-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# STEP 3 - Split the data. Split into train and test (for Crossvalidation).\n",
    "#\n",
    "\n",
    "train, test = dataframe.split_frame(ratios=[0.8], destination_frames=[\"train\", \"test\"], seed=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "geological-matthew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Performance on testdata: \n",
      " \n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 79480.17397775457\n",
      "RMSE: 281.9222835778587\n",
      "MAE: 201.41323693016932\n",
      "RMSLE: 0.006198023640633325\n",
      "Mean Residual Deviance: 79480.17397775457\n",
      "\n",
      "Performance on trainingdata: \n",
      " \n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 47025.55971366976\n",
      "RMSE: 216.85377495831094\n",
      "MAE: 157.24448661343834\n",
      "RMSLE: 0.004761168440103185\n",
      "Mean Residual Deviance: 47025.55971366976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# STEP 4 - creating a GBM classification model. Show the results, on both training and test data. \n",
    "# Show all the performance stats for training and testdata.\n",
    "#\n",
    "\n",
    "#\n",
    "# ignoring irrelevant fields for training in the dataset\n",
    "#\n",
    "target_variable = 'income'\n",
    "ignoreFields = [target_variable, 'id']\n",
    "input_variables = [i for i in train.names if i not in ignoreFields]\n",
    "\n",
    "#\n",
    "# using cross validation\n",
    "#\n",
    "gbm_model_1 = H2OGradientBoostingEstimator(model_id = \"gbm-coursera\", ntrees=60, nfolds=5, max_depth=5, learn_rate=0.2)\n",
    "gbm_model_1.train(input_variables, target_variable, train)\n",
    "\n",
    "#\n",
    "# showing model performance\n",
    "#\n",
    "print(\"Performance on testdata: \\n\", gbm_model_1.model_performance(test))\n",
    "print(\"Performance on trainingdata: \\n\",gbm_model_1.model_performance(train))\n",
    "\n",
    "#\n",
    "# storing the scoring results of model 1 for comparison\n",
    "#\n",
    "gbm_model_1_rmse = gbm_model_1.rmse(xval = True)\n",
    "gbm_model_1_mae = gbm_model_1.mae(xval = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "administrative-extreme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Performance on testdata: \n",
      " \n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 40752.463626682904\n",
      "RMSE: 201.87239441459772\n",
      "MAE: 131.96896280739773\n",
      "RMSLE: 0.004217003296384585\n",
      "Mean Residual Deviance: 40752.463626682904\n",
      "\n",
      "Performance on trainingdata: \n",
      " \n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 17985.186729576875\n",
      "RMSE: 134.10886148788555\n",
      "MAE: 93.9869185063788\n",
      "RMSLE: 0.002893957903522658\n",
      "Mean Residual Deviance: 17985.186729576875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# STEP 5 - try some alternative parameters, to build a different model, and show how the results differ.\n",
    "#\n",
    "\n",
    "#\n",
    "# using cross validation\n",
    "# changed parameters compared to the model above:\n",
    "# increased ntrees to 80, increased max_depth to 6, decreased the learn_rate to 0.01 (since using higher ntrees)\n",
    "# \n",
    "# Should give better results than the first model!\n",
    "#\n",
    "gbm_model_2 = H2OGradientBoostingEstimator(model_id = \"gbm-coursera-tweaked-params\", ntrees=80, nfolds=5, max_depth=6, learn_rate = 0.1)\n",
    "gbm_model_2.train(input_variables, target_variable, train)\n",
    "\n",
    "#\n",
    "# showing model performance\n",
    "#\n",
    "print(\"Performance on testdata: \\n\", gbm_model_2.model_performance(test))\n",
    "print(\"Performance on trainingdata: \\n\",gbm_model_2.model_performance(train))\n",
    "\n",
    "#\n",
    "# storing the scoring results of model 2 for comparison\n",
    "#\n",
    "gbm_model_2_rmse = gbm_model_2.rmse(xval = True)\n",
    "gbm_model_2_mae = gbm_model_2.mae(xval = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "liquid-metro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT COMPARISON:\n",
      "\n",
      "RMSE Model 1: 299.07816050028225 \n",
      " MAE Model 1: 208.76301456022514 \n",
      " \n",
      "RMSE Model 2 (Tweaked Parameters): 215.35022500251927 \n",
      " MAE Model 2 (Tweaked Parameters): 145.36858048765177\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# This section is to compare the scorings of both the first model and the second model (with tweaked parameters)\n",
    "#\n",
    "print(\"RESULT COMPARISON:\\n\")\n",
    "print(\"RMSE Model 1:\",gbm_model_1_rmse,\"\\n\",\"MAE Model 1:\",gbm_model_1_mae,\"\\n\",\"\\n\"\n",
    "      \"RMSE Model 2 (Tweaked Parameters):\",gbm_model_2_rmse,\"\\n\",\"MAE Model 2 (Tweaked Parameters):\",gbm_model_2_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-hotel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
